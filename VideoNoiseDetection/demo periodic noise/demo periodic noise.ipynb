{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b7326f-e9c5-4f50-b271-9f8fb574d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glitch_this import ImageGlitcher\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "import os\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc2e2aa-0a9f-4290-839d-394cd3606289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5c35b2-908e-489c-bc0d-0d44f0d54b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(path):\n",
    "    images_list = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            images_list.append(os.path.join(root, name))\n",
    "\n",
    "    return images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd295af-cade-4011-86e1-ca0961ba4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S_resize = 224\n",
    "# x = np.linspace(0, 1, S_resize)\n",
    "# y = np.linspace(0, 1, S_resize)\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "# periodic_noise = np.sin(32*np.pi*(X + Y/50))\n",
    "# result = img + 10*periodic_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8434de-63dc-4ade-b895-34f174ac9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_resize = 224\n",
    "x = np.linspace(0, 1, S_resize)\n",
    "y = np.linspace(0, 1, S_resize)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "def add_periodic_noise(img):\n",
    "    result = img\n",
    "    dense = np.random.randint(32,100)\n",
    "    alpha = np.random.randint(5,30)\n",
    "    \n",
    "    if np.random.randint(0,2) == 0:\n",
    "        a = np.random.randint(1,50)\n",
    "        b = 1\n",
    "    else:\n",
    "        a = 1\n",
    "        b = np.random.randint(1,50)\n",
    "    sin_periodic_noise = np.sin(dense*np.pi*(X/a + Y/b))\n",
    "    result = img + alpha*sin_periodic_noise\n",
    "    \n",
    "    if np.random.randint(0,2) == 1:\n",
    "        alpha_1 = np.random.randint(20,40)\n",
    "        dense_1 = np.random.randint(25,40)\n",
    "        result += alpha_1*np.cos(dense_1*np.pi*X)\n",
    "    return result.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a917843-1fa7-45df-abab-ed143afdcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, target, transform=None):\n",
    "        self.root = root\n",
    "        self.images = get_images(root)\n",
    "        self.targets = [int(target) for i in range(len(self.images))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.images[index]  \n",
    "        image = PIL.ImageOps.grayscale(PIL.Image.open(image_name))\n",
    "        label = torch.tensor(self.targets[index],dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bb5089-6d08-4ec5-8c1f-132f6bb897e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../Data/505_video_frames/\"\n",
    "batch_size=32\n",
    "\n",
    "normal_transform = transforms.Compose([\n",
    "        transforms.Resize((S_resize,S_resize)),           \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.456],\n",
    "                             [0.227])\n",
    "    ])\n",
    "\n",
    "periodic_transform = transforms.Compose([\n",
    "        transforms.Resize((S_resize,S_resize)),      \n",
    "        transforms.Lambda(add_periodic_noise),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.456],\n",
    "                             [0.227])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e7e9c0c-6557-42bf-a719-ea492288452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = CustomDataset(root=root,target=0,transform=normal_transform)\n",
    "noised_dataset = CustomDataset(root=root,target=1,transform=periodic_transform)\n",
    "dataset = ConcatDataset([original_dataset, noised_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422e57ba-875e-4bfc-a0a0-c365dbae8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.456/0.227],\n",
    "    std=[1/0.227]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee987a00-5b51-4df1-9c07-286dd3412fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6 * len(dataset))\n",
    "validation_size = int((len(dataset) - train_size)/2)\n",
    "test_size = int(len(dataset) - train_size - validation_size)\n",
    "train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size, test_size]) #6 2 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7921e82b-66b0-4c13-9f1e-457c27de2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.456/0.227],\n",
    "    std=[1/0.227]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4049d717-9870-4d37-a8c1-ec2114fcfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_inv = inv_normalize(train_dataset[150][0])\n",
    "# plt.imshow(np.transpose(im_inv.numpy(), (1, 2, 0)),cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d7c051-1dcd-4bdc-a47b-4e113c71c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a302bc6c-1702-4abb-b937-1c9c73dd65d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3428"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d953bcc8-b53a-4e2a-8c13-c62a6e98144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicNoiseDetect(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,3,1)\n",
    "        self.conv2 = nn.Conv2d(6,16,3,1)\n",
    "        self.conv3 = nn.Conv2d(16,32,3,1)\n",
    "        self.conv4 = nn.Conv2d(32,64,3,1)\n",
    "        self.conv5 = nn.Conv2d(64,64,3,1)\n",
    "        self.fc1 = nn.Linear(1600,512)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(512,1)  \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "\n",
    "        x = x.view(-1,1600)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1f624c0-5892-4cee-a904-4ba817f680cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeriodicNoiseDetect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbfb7765-f641-4b77-a616-a6ea89c2159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "PeriodicNoiseDetect                      [32, 1]                   --\n",
      "├─Conv2d: 1-1                            [32, 6, 222, 222]         60\n",
      "├─Conv2d: 1-2                            [32, 16, 109, 109]        880\n",
      "├─Conv2d: 1-3                            [32, 32, 52, 52]          4,640\n",
      "├─Conv2d: 1-4                            [32, 64, 24, 24]          18,496\n",
      "├─Conv2d: 1-5                            [32, 64, 10, 10]          36,928\n",
      "├─Linear: 1-6                            [32, 512]                 819,712\n",
      "├─Dropout: 1-7                           [32, 512]                 --\n",
      "├─Linear: 1-8                            [32, 1]                   513\n",
      "==========================================================================================\n",
      "Total params: 881,229\n",
      "Trainable params: 881,229\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.32\n",
      "==========================================================================================\n",
      "Input size (MB): 6.42\n",
      "Forward/backward pass size (MB): 157.72\n",
      "Params size (MB): 3.52\n",
      "Estimated Total Size (MB): 167.67\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(batch_size, 1, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9a643b-c137-4b38-a6bd-a98fadac9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=2, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss and abs(validation_loss - self.min_validation_loss) > self.min_delta:\n",
    "            self.counter = 0\n",
    "            self.min_validation_loss = validation_loss\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience and validation_loss < 0.01 :\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15cb4d01-17e8-47ca-acc3-3a5080282656",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.00001,weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.1,patience=2,verbose=True)\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "247ace69-411f-4a96-a365-a5d31eeaac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      54\n",
      "       6\n",
      "     864\n",
      "      16\n",
      "    4608\n",
      "      32\n",
      "   18432\n",
      "      64\n",
      "   36864\n",
      "      64\n",
      "  819200\n",
      "     512\n",
      "     512\n",
      "       1\n",
      "________\n",
      "  881229\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>8}')\n",
    "    print(f'________\\n{sum(params):>8}')\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fcd134a-d76e-43dd-81b0-1945efcd5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab6c0eed-3489-4a78-8819-a588e1909e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#push data to GPU\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 11\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Apply the model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "# train_losses = []\n",
    "# test_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    for b, (X_train, y_train) in tqdm(enumerate(train_loader)):\n",
    "        b+=1\n",
    "        #push data to GPU\n",
    "        model.train()\n",
    "        X_train = X_train.to(device='cuda')\n",
    "        y_train = y_train.to(device='cuda')\n",
    "        # Apply the model\n",
    "        pred = model(X_train)\n",
    "        loss = criterion(pred, y_train.unsqueeze(dim=-1))\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print interim results\n",
    "        if b % 100 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{batch_size*b:6}/{len(train_loader)}]  loss: {loss.item()}')\n",
    "        \n",
    "        if early_stopper.early_stop(loss):             \n",
    "            break\n",
    "    # train_losses.append(loss.item())\n",
    "\n",
    "    running_loss = 0    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for vb, (X_test, y_test) in enumerate(test_loader):\n",
    "            #push data to GPU\n",
    "            X_test = X_test.cuda()\n",
    "            y_test = y_test.cuda()\n",
    "            # Apply the model\n",
    "            val = model(X_test)\n",
    "            loss = criterion(val, y_test.unsqueeze(dim=-1))\n",
    "            running_loss += loss\n",
    "    \n",
    "    # test_losses.append(loss)\n",
    "    avg_loss = running_loss / (vb+1)\n",
    "    print(f'epoch: {i:2}  finished   validation loss: {avg_loss.item():10.8f}')\n",
    "    scheduler.step(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1229e-7fd3-4e80-84ab-be50b1d5a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in tqdm(test_loader):\n",
    "        X_test = X_test.to(device='cuda')\n",
    "        y_test = y_test.to(device='cuda')\n",
    "        y_val = model(X_test)\n",
    "        predicted = torch.round(y_val)\n",
    "        correct += (predicted == y_test.unsqueeze(dim=-1)).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_dataset)} = {correct.item()*100/len(test_dataset):7.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aade848-5612-4afa-a8fa-1b1f1e094a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_path = '../castle.jpg'\n",
    "new_sample = PIL.ImageOps.grayscale(PIL.Image.open(new_sample_path))\n",
    "# new_sample = new_sample.resize((S_resize,S_resize))\n",
    "# # new_sample = add_periodic_noise(new_sample)\n",
    "# new_sample += 30*np.cos(100*np.pi*X)\n",
    "\n",
    "\n",
    "plt.imshow(new_sample,cmap='gray')\n",
    "# new_sample = PIL.Image.fromarray(np.uint8(new_sample)).convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3be8d-2d16-457d-ae52-f7db33aa330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = normal_transform(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9435da5-557b-4cc6-9914-a4500148d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.456/0.227],\n",
    "    std=[1/0.227]\n",
    ")\n",
    "im_inv = inv_normalize(img)\n",
    "plt.imshow(np.transpose(im_inv.numpy(), (1, 2, 0)),cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ba81f-5079-4b13-b96f-df311e46136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    img = img.unsqueeze(dim=0)\n",
    "    print(img.size())\n",
    "    print(model(img.to(device='cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaacefa-398a-4180-b300-65b1ccc7f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f482e40-b166-42de-ac97-420695f7ce1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
